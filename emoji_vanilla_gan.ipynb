{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DCGenerator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59ddcd0ab291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_emoji_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDCGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDCDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DCGenerator'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Numpy & Scipy imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "from data_loader import get_emoji_loader\n",
    "from models import DCGenerator, DCDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 11\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(G, D):\n",
    "    \"\"\"Prints model information for the generators and discriminators.\n",
    "    \"\"\"\n",
    "    print(\"                    G                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(G)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    print(\"                    D                  \")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(D)\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "def create_model(opts):\n",
    "    \"\"\"Builds the generators and discriminators.\n",
    "    \"\"\"\n",
    "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.conv_dim)\n",
    "    D = DCDiscriminator(conv_dim=opts.conv_dim)\n",
    "\n",
    "    print_models(G, D)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "\n",
    "    return G, D\n",
    "\n",
    "\n",
    "def checkpoint(iteration, G, D, opts):\n",
    "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
    "    \"\"\"\n",
    "    G_path = os.path.join(opts.checkpoint_dir, 'G.pkl')\n",
    "    D_path = os.path.join(opts.checkpoint_dir, 'D.pkl')\n",
    "    torch.save(G.state_dict(), G_path)\n",
    "    torch.save(D.state_dict(), D_path)\n",
    "\n",
    "\n",
    "def create_image_grid(array, ncols=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_images, channels, cell_h, cell_w = array.shape\n",
    "\n",
    "    if not ncols:\n",
    "        ncols = int(np.sqrt(num_images))\n",
    "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
    "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
    "    for i in range(0, nrows):\n",
    "        for j in range(0, ncols):\n",
    "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j].transpose(1, 2, 0)\n",
    "\n",
    "    if channels == 1:\n",
    "        result = result.squeeze()\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_samples(G, fixed_noise, iteration, opts):\n",
    "    generated_images = G(fixed_noise)\n",
    "    generated_images = utils.to_data(generated_images)\n",
    "\n",
    "    grid = create_image_grid(generated_images)\n",
    "\n",
    "    # merged = merge_images(X, fake_Y, opts)\n",
    "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
    "    scipy.misc.imsave(path, grid)\n",
    "    print('Saved {}'.format(path))\n",
    "\n",
    "\n",
    "def sample_noise(dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Variable of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "\n",
    "    Output:\n",
    "    - A PyTorch Variable of shape (batch_size, dim, 1, 1) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    return utils.to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_dataloader, opts):\n",
    "    \"\"\"Runs the training loop.\n",
    "        * Saves checkpoints every opts.checkpoint_every iterations\n",
    "        * Saves generated samples every opts.sample_every iterations\n",
    "    \"\"\"\n",
    "\n",
    "    # Create generators and discriminators\n",
    "    G, D = create_model(opts)\n",
    "\n",
    "    # Create optimizers for the generators and discriminators\n",
    "    g_optimizer = optim.Adam(G.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "    d_optimizer = optim.Adam(D.parameters(), opts.lr, [opts.beta1, opts.beta2])\n",
    "\n",
    "    # Generate fixed noise for sampling from the generator\n",
    "    fixed_noise = sample_noise(opts.noise_size)  # batch_size x noise_size x 1 x 1\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    total_train_iters = opts.num_epochs * len(train_dataloader)\n",
    "\n",
    "    for epoch in range(opts.num_epochs):\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            real_images, labels = batch\n",
    "            real_images, labels = utils.to_var(real_images), utils.to_var(labels).long().squeeze()\n",
    "\n",
    "            ################################################\n",
    "            ###         TRAIN THE DISCRIMINATOR         ####\n",
    "            ################################################\n",
    "\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Compute the discriminator loss on real images\n",
    "            # D_real_loss = ...\n",
    "\n",
    "            # 2. Sample noise\n",
    "            # noise = ...\n",
    "\n",
    "            # 3. Generate fake images from the noise\n",
    "            # fake_images = ...\n",
    "\n",
    "            # 4. Compute the discriminator loss on the fake images\n",
    "            # D_fake_loss = ...\n",
    "\n",
    "            # 5. Compute the total discriminator loss\n",
    "            # D_total_loss = ...\n",
    "\n",
    "            D_total_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            ###########################################\n",
    "            ###          TRAIN THE GENERATOR        ###\n",
    "            ###########################################\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Sample noise\n",
    "            # noise = ...\n",
    "\n",
    "            # 2. Generate fake images from the noise\n",
    "            # fake_images = ...\n",
    "\n",
    "            # 3. Compute the generator loss\n",
    "            # G_loss = ...\n",
    "\n",
    "            G_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "\n",
    "            # Print the log info\n",
    "            if iteration % opts.log_step == 0:\n",
    "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
    "                       iteration, total_train_iters, D_real_loss.data[0], D_fake_loss.data[0], G_loss.data[0]))\n",
    "\n",
    "            # Save the generated samples\n",
    "            if iteration % opts.sample_every == 0:\n",
    "                save_samples(G, fixed_noise, iteration, opts)\n",
    "\n",
    "            # Save the model parameters\n",
    "            if iteration % opts.checkpoint_every == 0:\n",
    "                checkpoint(iteration, G, D, opts)\n",
    "\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(opts):\n",
    "    \"\"\"Loads the data, creates checkpoint and sample directories, and starts the training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dataloader for the training images\n",
    "    train_dataloader, _ = get_emoji_loader(opts.emoji, opts)\n",
    "\n",
    "    # Create checkpoint and sample directories\n",
    "    utils.create_dir(opts.checkpoint_dir)\n",
    "    utils.create_dir(opts.sample_dir)\n",
    "\n",
    "    training_loop(train_dataloader, opts)\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    \"\"\"Creates a parser for command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model hyper-parameters\n",
    "    parser.add_argument('--image_size', type=int, default=32, help='The side length N to convert images to NxN.')\n",
    "    parser.add_argument('--conv_dim', type=int, default=32)\n",
    "    parser.add_argument('--noise_size', type=int, default=100)\n",
    "\n",
    "    # Training hyper-parameters\n",
    "    parser.add_argument('--num_epochs', type=int, default=40)\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='The number of images in a batch.')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')\n",
    "    parser.add_argument('--lr', type=float, default=0.0003, help='The learning rate (default 0.0003)')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5)\n",
    "    parser.add_argument('--beta2', type=float, default=0.999)\n",
    "\n",
    "    # Data sources\n",
    "    parser.add_argument('--emoji', type=str, default='Apple', choices=['Apple', 'Facebook', 'Windows'], help='Choose the type of emojis to generate.')\n",
    "\n",
    "    # Directories and checkpoint/sample iterations\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_vanilla')\n",
    "    parser.add_argument('--sample_dir', type=str, default='./samples_vanilla')\n",
    "    parser.add_argument('--log_step', type=int , default=10)\n",
    "    parser.add_argument('--sample_every', type=int , default=200)\n",
    "    parser.add_argument('--checkpoint_every', type=int , default=400)\n",
    "\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_size IMAGE_SIZE]\n",
      "                             [--conv_dim CONV_DIM] [--noise_size NOISE_SIZE]\n",
      "                             [--num_epochs NUM_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--num_workers NUM_WORKERS] [--lr LR]\n",
      "                             [--beta1 BETA1] [--beta2 BETA2]\n",
      "                             [--emoji {Apple,Facebook,Windows}]\n",
      "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                             [--sample_dir SAMPLE_DIR] [--log_step LOG_STEP]\n",
      "                             [--sample_every SAMPLE_EVERY]\n",
      "                             [--checkpoint_every CHECKPOINT_EVERY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ccruz27/.local/share/jupyter/runtime/kernel-f8343977-201d-483b-9e66-ba155d209a7f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = create_parser()\n",
    "    opts = parser.parse_args()\n",
    "\n",
    "    batch_size = opts.batch_size\n",
    "\n",
    "    print(opts)\n",
    "    main(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
